**项目简介（可放简历开头 2–3 行）**  
ZBStorage 是我主导研发的“分布式智能分层存储系统”（国家级科研项目），面向 SSD/HDD/光盘库等异构介质，提供统一的类 POSIX 文件系统接口与多介质分层管理能力。项目聚焦海量元数据、高并发访问与资源规划仿真，为未来在 AI/大数据场景下落地智能分层调度和自治运维预留了完整的技术基础。
--
**技术难点与解决的任务场景（4 点）**
1. **异构介质统一命名空间与类 POSIX 语义**  
   - 场景任务：上层业务希望在混合 SSD/HDD/光盘库的复杂环境中，仍像使用本地文件系统一样进行常规读写与目录操作，而不感知底层介质差异。  
   - 技术方案：自研元数据服务（MDS）与 VFS 层，设计 `Inode` / `DirectoryEntry` / `ZBSS_dirent` 等核心结构，统一权限模型与路径规则（`ZB_NAME_MAX`/`ZB_PATH_MAX`），通过 `ZBSS_DIR + readdir` 实现类 POSIX 的目录遍历语义，为后续接入 FUSE/内核 VFS 预留接口。
2. **百万级文件的冷热分层建模与元数据大规模合成**  
   - 场景任务：在没有真实完整业务数据的前提下，需要对 PB 级文件系统的冷热分层策略、迁移策略等进行模拟评估，并能反复复现实验结果。  
   - 技术方案：在 `InodeStorage::BatchGenerationConfig` 中抽象“温度模型 + 目录树结构 + 节点分布”，一次性生成百万级 inode。利用 hot/warm/cold 比例与大小范围建模冷热数据分布，以 `root_path + dir_depth + dir_fanout` 自动构造层次目录树，并为每个 inode 分配节点类型和块布局，输出为结构化二进制，形成可控、可复现的测试数据集。
3. **万级节点与光盘库的统一资源图建模与持久化**  
   - 场景任务：在国家级数据中心规划阶段，需要在无真实硬件集群的情况下，虚拟出上万存储节点、数万光盘库的资源拓扑，对节点规模、混部比例、布局策略进行快速组合仿真。  
   - 技术方案：通过 `StorageNode + StorageResource` 二层抽象批量生成 `ssd_node_i` / `hdd_node_i` / `mix_node_i` 及大量 `OpticalDiscLibrary`，构成虚拟资源池；利用 `nodeRank + sortUninitializedById` 对节点排序，形成适合调度算法使用的“资源图”；再通过 `nlohmann_json` 实现拓扑的 `saveToFile/loadFromFile`，支持资源图的快照、迁移与回放。
4. **统一 I/O 抽象与可插拔性能仿真框架，支撑未来智能调度**  
   - 场景任务：在缺乏完整硬件环境时，需要对不同节点/介质/布局下的 I/O 行为和性能瓶颈进行快速迭代评估，并为未来接入 AI 调度算法预留代价模型接口。  
   - 技术方案：统一设计 `IORequest` 与 `StorageResource::processIO` 接口，将 I/O 抽象为“类型 + 节点 ID + 卷 ID + 块偏移”的通用结构，支持基于 `/mnt/md0/node/...` 的文件级仿真与真实 `StorageNode` 路径共存；为不同设备注入带宽、时延等参数构建统一性能模型，并通过轻量日志 `ZBLog` + 测试工程收集 I/O 轨迹和节点状态，为后续引入 ML/强化学习做智能分层与调度预留数据与接口。
